{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Week 6: Capstone project\n",
    "\n",
    "* Week 5 recap\n",
    "  * Predictive analytics using statsmodels\n",
    "  * Predictive anlaytics using scikit-learn\n",
    "* Week 6\n",
    "  * No discussion post required for the week\n",
    "  * Capston project\n",
    "    * Due end of course\n",
    "    * Scoring rubric\n",
    "    * Components of the capstone project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Week 5 recap\n",
    "* Predictive vs. descriptive analytics\n",
    "  * Descriptive statistics provide summary of existing data\n",
    "  * Predictive statistics allows us to make conclusion outside of existing data\n",
    "* Descriptive statistics\n",
    "  * Univariate\n",
    "    * mean/std/percentiles\n",
    "  * Multivariate\n",
    "    * correlation/covariance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import statsmodels\n",
    "from patsy import dmatrices\n",
    "import scipy.stats\n",
    "from statsmodels.stats import weightstats as weightstats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statsmodels (https://www.statsmodels.org)\n",
    "\n",
    "* Python module that provides functions and classes for statistical tests and models\n",
    "* Simulates R like 'formula' syntax, but provides tight integration with Pandas dataframe\n",
    "* Functionality\n",
    "  * Statistical tests\n",
    "  * Linear Regression\n",
    "  * Logistical Regression (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Minimal example\n",
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear regression\n",
    "* Predicting continuous valued response variable\n",
    "* Predictor variables can be continuous/discrete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "results = smf.ols('tip ~ total_bill', data = tips).fit()\n",
    "print(results.params)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(tips['total_bill'], tips['tip'], '.')\n",
    "plt.plot(tips['total_bill'], results.fittedvalues, '.')\n",
    "plt.legend(['actual tip', 'predicted tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "* Instead of predicting actual tip, we'd like to predict if tip percentage > 20%\n",
    "* This is an example where response variable is categorical (True , False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tips['tip_gt_20'] = (tips['tip']/tips['total_bill']  > 0.2).astype(np.float32)\n",
    "tips['tip_gt_20'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "y, X = dmatrices('tip_gt_20 ~ total_bill', data=tips)\n",
    "model = smf.Logit(y, X)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "yhat = result.predict(X)\n",
    "sns.distplot(yhat[y[:,0] > 0])\n",
    "sns.distplot(yhat[y[:,0] == 0])\n",
    "plt.legend(['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('Classification report')\n",
    "import sklearn.metrics\n",
    "yhat = result.predict(X) > 0.15\n",
    "print(sklearn.metrics.classification_report(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit learn (http://scikit-learn.org)\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_thumb.png\">\n",
    "</div>\n",
    "\n",
    "* Python library for data mining, data analysis and machine learning\n",
    "* Built on top of numpy, scipy and matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression using sklearn\n",
    "* Dataframes need to be converted to numeric matrices using patsy\n",
    "* Can use non-linear techniques for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "\n",
    "y,X = dmatrices('tip ~ total_bill', data=tips)\n",
    "res = model.fit(X, y)\n",
    "plt.plot(X[:,1], y, '.')\n",
    "plt.plot(X[:,1], model.predict(X), '.')\n",
    "plt.legend(['actual tip', 'predicted tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Non linear (tree based) regression model\n",
    "from sklearn import ensemble\n",
    "model = sklearn.ensemble.RandomForestRegressor()\n",
    "model.fit(X,y)\n",
    "plt.plot(X[:,1], y, 'r.')\n",
    "plt.plot(X[:,1], model.predict(X), 'g.')\n",
    "plt.legend(['actual tip', 'predicted tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "* Instead of predicting actual tip, we'd like to predict if tip percentage > 20%\n",
    "* This is an example where response variable is categorical (True , False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model \n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression(C=0.1)\n",
    "y,X = dmatrices('tip_gt_20 ~ total_bill + sex + time + day', data=tips)\n",
    "model.fit(X, y)\n",
    "yhat = model.predict(X)\n",
    "print(sklearn.metrics.classification_report(y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "yhat = model.predict_proba(X)\n",
    "sns.distplot(yhat[y[:,0] > 0, 1])\n",
    "sns.distplot(yhat[y[:,0] == 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Non linear model\n",
    "import sklearn.ensemble\n",
    "y, X = dmatrices('tip_gt_20 ~ total_bill', data=tips)\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "model.fit(X,y)\n",
    "yhat = model.predict(X)\n",
    "print(sklearn.metrics.classification_report(y, yhat.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "yhat = model.predict_proba(X)\n",
    "sns.distplot(yhat[y[:,0] > 0, 1])\n",
    "sns.distplot(yhat[y[:,0] == 0, 1])\n",
    "plt.legend(['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
